{
	"name": "jobs-ETL",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "SilverSpark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 1,
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "4",
				"spark.autotune.trackingId": "23317acb-14ad-4669-bfe2-a1185f83ba2d"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/7ce1bb29-7a9b-473d-a49e-a335cd2f0e33/resourceGroups/datawarehouse-rg/providers/Microsoft.Synapse/workspaces/my-synapse/bigDataPools/SilverSpark",
				"name": "SilverSpark",
				"type": "Spark",
				"endpoint": "https://my-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SilverSpark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.5",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import col, to_date,udf\n",
					"from pyspark.sql.types import ArrayType, StringType\n",
					"from pyspark.sql.functions import year, month, dayofmonth\n",
					"from pyspark.sql import functions as F\n",
					"import re"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					"keywords={\n",
					"    'ember.js', 'trello', 'symfony', 'laravel', 'javascript', 'ansible', 'zoom', 'monday.com', 'lisp', 'asp.net core', 'rust', 'groovy', 'terminal', 'asp.net', 'excel', 'objective-c', 'angular', 'C', 'bigquery', 'microstrategy', 'react.js', 'dplyr', 'nuxt.js', 'deno', 'crystal', 'unify', 'atlassian', 'sql server', 'python', 'ssis', 'sap', 'f#', 'ionic', 'vue.js', 'digitalocean', 'redis', 'ocaml', 'nosql', 'shell', 'word', 'gtx', 'clojure', 'scala', 'elasticsearch', 'powerpoint', 'phoenix', 'git', 'unix', 'homebrew', 'dax', 'php', 'vmware', 'elixir', 'suse', 'centos', 'wrike', 'puppet', 'dynamodb', 'couchbase', 'kali', 'smartsheet', 'hugging face', 'mlpack', 'dart', 'pulumi', 'rshiny', 'fastify', 'unreal', 'vue', 'visual basic', 'nuix', 'fastapi', 'kubernetes', 'matlab', 'bitbucket', 'perl', 'keras', 'nltk', 'mattermost', 'sas', 'sql', 'lua', 'capacitor', 'flow', 'airtable', 'apl', 'graphql', 'ubuntu', 'yarn', 'node.js', 'redhat', 'fortran', 'arch', 'notion', 'qt', 'hadoop', 'opencv', 'theano', 'matplotlib', 'db2', 'assembly', 'kafka', 'scikit-learn', 'cassandra', 'gatsby', 'wimi', 'debian', 'mariadb', 'pyspark', 'visualbasic', 'svn', 'no-sql', 'asana', 'mxnet', 'chainer', 'linode', 'workfront', 'gcp', 'sqlserver', 'jquery', 'redshift', 'delphi', 'twilio', 'julia', 'swift', 'unity', 'neo4j', 'spark', 'vba', 'openstack', 'java', 'docker', 'play framework', 'esquisse', 'rocketchat', 'xamarin', 'ssrs', 'haskell', 'next.js', 'R', 'confluence', 'asp.netcore', 'planner', 'qlik', 'terraform', 'bash', 'powershell', 'ggplot2', 'dlib', 'electron', 'ruby on rails', 'blazor', 'angular.js', 'golang', 'spreadsheet', 'ibm cloud', 'gdpr', 'react', 'tidyr', 'microsoft lists', 'mongo', 'ringcentral', 'wire', 'spring', 'flask', 'aws', 'npm', 'c#', 'html', 'css', 'clickup', 'datarobot', 'cobol', 'ovh', 'couchdb', 'shogun', 'splunk', 'sass', 'flutter', 't-sql', 'codecommit', 'symphony', 'chef', 'rubyon rails', 'mlr', 'microsoft teams', 'ruby', 'linux', 'dingtalk', 'pascal', 'msaccess', 'looker', 'gitlab', 'drupal', 'airflow', 'seaborn', 'wsl', 'firestore', 'cognos', 'c++', 'fedora', 'sheets', 'numpy', 'plotly', 'github', 'power bi', 'colocation', 'typescript', 'sharepoint', 'mysql', 'svelte', 'jira', 'heroku', 'postgresql', 'sqlite', 'azure', 'vb.net', 'webex', 'tableau', 'databricks', 'kotlin', 'erlang', 'node', 'pytorch', 'alteryx', 'django', 'solidity', 'mongodb', 'outlook', 'tidyverse', 'windows', 'ms access', 'snowflake', 'selenium', 'slack', 'powerbi', 'cordova', 'huggingface', 'watson', 'jupyter', 'aurora', 'firebase', 'visio', 'express', 'oracle', 'google chat', 'spss', 'macos', 'jenkins', 'tensorflow', 'pandas'}"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"spark = SparkSession.builder.getOrCreate()\n",
					"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
					"\n",
					""
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"bronze_jobs_path = \"abfss://bronze@datalakeyassin.dfs.core.windows.net/jobs/\"\n",
					"silver_jobs_path = \"abfss://silver@datalakeyassin.dfs.core.windows.net/jobs/\"\n",
					"gold_jobs_path = \"abfss://gold@datalakeyassin.dfs.core.windows.net/jobs/\""
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"source": [
					"bronze_jobs_path = \"abfss://bronze@datalakeyassin.dfs.core.windows.net/jobs/\"\n",
					"silver_jobs_path = \"abfss://silver@datalakeyassin.dfs.core.windows.net/jobs/\"\n",
					"\n",
					"\n",
					"columns_map = {\n",
					"    \"data_jobs1.csv\": [\"Role\", \"Location\", \"Posted_Date\", \"Skills\"],\n",
					"    \"data_jobs2.csv\": [\"job_title_short\", \"job_location\", \"job_posted_date\", \"job_skills\"],\n",
					"    \"data_jobs3.csv\": [\"job_title\", \"full_address\", \"job_posted_date\", \"job_description_text\"],\n",
					"    \"data_jobs4.csv\": [\"title\", \"location\", \"job_posted_date\", \"skills\"],\n",
					"    \"data_jobs5.csv\": [\"title\", \"location\", \"posted_date\", \"description\"]\n",
					"}\n",
					"\n",
					"\n",
					"unique_cols = [\"job_title\", \"job_location\", \"job_posted_date\", \"job_skills\"]\n",
					"\n",
					"df_list = []\n",
					"for file_name, cols_to_keep in columns_map.items():\n",
					"    df = spark.read.option(\"header\", True).csv(f\"{bronze_jobs_path}{file_name}\")\n",
					"    df = df.select([col(c) for c in cols_to_keep])\n",
					"\n",
					"    for old_col, new_col in zip(cols_to_keep, unique_cols):\n",
					"        df = df.withColumnRenamed(old_col, new_col)\n",
					"    df_list.append(df)\n",
					"\n",
					"df_jobs = df_list[0]\n",
					"for df in df_list[1:]:\n",
					"    df_jobs = df_jobs.unionByName(df)\n",
					"\n",
					"\n",
					"df_jobs = df_jobs.withColumn(\"job_posted_date\", to_date(col(\"job_posted_date\"), \"yyyy-MM-dd\"))"
				],
				"execution_count": 20
			},
			{
				"cell_type": "code",
				"source": [
					"def extract_tools(text):\n",
					"    found = []\n",
					"    if text:\n",
					"        for kw in keywords:\n",
					"            if len(kw) <= 2:\n",
					"                pattern = r'\\b' + re.escape(kw) + r'\\b'\n",
					"                if re.search(pattern, text):\n",
					"                    found.append(kw)\n",
					"            else:\n",
					"                pattern = r'\\b' + re.escape(kw.lower()) + r'\\b'\n",
					"                if re.search(pattern, text.lower()):\n",
					"                    found.append(kw)\n",
					"    return found\n",
					"\n",
					"extract_tools_spark_udf = udf(extract_tools, ArrayType(StringType()))"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"df_jobs = df_jobs.withColumn(\"tools\", extract_tools_spark_udf(\"job_skills\"))"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"source": [
					"it_job_titles = [\n",
					"    \"Data Scientist\", \"Data Analyst\", \"Business Analyst\", \"Data Engineer\",\n",
					"    \"Machine Learning Engineer\", \"ML Ops Engineer\", \"NLP Engineer\", \"Computer Vision Engineer\",\n",
					"    \"Software Engineer\", \"Backend Engineer\", \"Frontend Engineer\", \"Full Stack Engineer\",\n",
					"    \"Mobile App Developer\", \"DevOps Engineer\", \"Cloud Engineer\",\n",
					"    \"Python Developer\", \"Java Developer\", \"PHP Developer\", \"Angular Developer\", \"Vue.js Developer\",\n",
					"    \"Database Developer\", \"ETL Developer\"\n",
					"]\n",
					"\n",
					"def match_job(title):\n",
					"    if not title:\n",
					"        return None\n",
					"    title_lower = title.lower()\n",
					"    for job in it_job_titles:\n",
					"        if job.lower() in title_lower:\n",
					"            return job\n",
					"    return title  # fallback: keep original\n",
					"\n",
					"match_job_udf = udf(match_job, StringType())\n",
					"\n",
					"df_jobs = df_jobs.withColumn(\"job_name\", match_job_udf(\"job_title\"))\n",
					""
				],
				"execution_count": 23
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"\n",
					"df_jobs = df_jobs.withColumn(\"year\", year(\"job_posted_date\")) \\\n",
					"                      .withColumn(\"month\", month(\"job_posted_date\")) \\\n",
					"                      .withColumn(\"day\", dayofmonth(\"job_posted_date\")) \\\n",
					"                      .select(\"job_name\", \"job_location\", \"job_posted_date\", \"tools\", \"year\", \"month\", \"day\")\n",
					""
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"source": [
					"df_jobs.show(5)"
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"source": [
					"df_github.write.mode(\"append\").partitionBy(\"year\", \"month\").parquet(silver_jobs_path)"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"staging_jobs = (\n",
					"    df_jobs\n",
					"    .withColumn(\"skill\", F.explode(\"tools\"))   \n",
					"    .groupBy(\"job_name\", \"skill\", \"job_location\", \"year\", \"month\", \"day\")\n",
					"    .agg(\n",
					"        F.count(\"*\").alias(\"job_postings\")  # number of postings for this job+skill+location+dat\n",
					"    )\n",
					")\n",
					"\n",
					"staging_jobs.show(10)\n",
					""
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"source": [
					"staging_social.write.mode(\"append\").parquet(gold_jobs_path)"
				],
				"execution_count": 28
			}
		]
	}
}